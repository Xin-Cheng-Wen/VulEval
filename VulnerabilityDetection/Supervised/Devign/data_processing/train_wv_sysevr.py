import argparse
from gensim.models import Word2Vec
import json
import os
from tqdm import trange


def train(data_paths, save_model_dir, model_name='default', min_occ=1, embedding_size=100, epochs=3):
    files = data_paths
    sentences = []
    for f in files:
        data = json.load(open(f))
        for e in data:
            code = e['tokenized']
            sentences.append([token.strip() for token in code.split()])
    print(len(sentences))
    wvmodel = Word2Vec(sentences, min_count=min_occ, workers=8, size=embedding_size)
    print('Embedding Size : ', wvmodel.vector_size)
    for i in trange(epochs, desc='> Training'):
        wvmodel.train(sentences, total_examples=len(sentences), epochs=1)
    if not os.path.exists(save_model_dir):
        os.mkdir(save_model_dir)
    save_file_path = os.path.join(save_model_dir, model_name)
    wvmodel.save(save_file_path)

files = [
    '../data/train_data_with_slices.json',
]

train(files, '../data/Word2Vec')
