## test

# python run.py --output_dir=./saved_models/test --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_train --train_data_file=../dataset/part/test/train_c_cpp.jsonl --eval_data_file=../dataset/part/test/valid_c_cpp.jsonl --test_data_file=../dataset/part/test/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee train_test.log

# python run.py --output_dir=./saved_models/test --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_eval --do_test --train_data_file=../dataset/part/test/train_c_cpp.jsonl --eval_data_file=../dataset/part/test/valid_c_cpp.jsonl --test_data_file=../dataset/part/test/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee test_test.log

# python ../evaluator/evaluator.py -a ../dataset/part/test/test_c_cpp.jsonl -p saved_models/test/predictions.txt


## random

# python run.py --output_dir=./saved_models/random --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_train --train_data_file=../dataset/all/random/train_c_cpp.jsonl --eval_data_file=../dataset/all/random/valid_c_cpp.jsonl --test_data_file=../dataset/all/random/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee train_random.log

# python run.py --output_dir=./saved_models/random --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_eval --do_test --train_data_file=../dataset/all/random/train_c_cpp.jsonl --eval_data_file=../dataset/all/random/valid_c_cpp.jsonl --test_data_file=../dataset/all/random/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee test_random.log

python ../evaluator/evaluator.py -a ../dataset/all/random/test_c_cpp.jsonl -p saved_models/random/predictions.txt


## time

# python run.py --output_dir=./saved_models/time --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_train --train_data_file=../dataset/all/time/train_c_cpp.jsonl --eval_data_file=../dataset/all/time/valid_c_cpp.jsonl --test_data_file=../dataset/all/time/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee train_time.log

# python run.py --output_dir=./saved_models/time --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_eval --do_test --train_data_file=../dataset/all/time/train_c_cpp.jsonl --eval_data_file=../dataset/all/time/valid_c_cpp.jsonl --test_data_file=../dataset/all/time/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee test_time.log

python ../evaluator/evaluator.py -a ../dataset/all/time/test_c_cpp.jsonl -p saved_models/time/predictions.txt

## commit

# python run.py --output_dir=./saved_models/commit --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_train --train_data_file=../dataset/all/commit/train_c_cpp.jsonl --eval_data_file=../dataset/all/commit/valid_c_cpp.jsonl --test_data_file=../dataset/all/commit/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee train_commit.log

# python run.py --output_dir=./saved_models/commit --model_type=roberta --tokenizer_name=../models/codebert --model_name_or_path=../models/codebert --do_eval --do_test --train_data_file=../dataset/all/commit/train_c_cpp.jsonl --eval_data_file=../dataset/all/commit/valid_c_cpp.jsonl --test_data_file=../dataset/all/commit/test_c_cpp.jsonl --epoch 8 --block_size 512 --train_batch_size 40 --eval_batch_size 64 --learning_rate 2e-5 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --d_size 128 --pkl_file=short_3path_cdata_nobalance.pkl 2>&1 | tee test_commit.log

python ../evaluator/evaluator.py -a ../dataset/all/commit/test_c_cpp.jsonl -p saved_models/commit/predictions.txt